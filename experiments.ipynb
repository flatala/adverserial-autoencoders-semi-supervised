{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset, Dataset\n",
    "from torch import nn\n",
    "from aae import SemiSupervisedAutoEncoderOptions, SemiSupervisedAdversarialAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "print(\"CUDA_VISIBLE_DEVICES:\", os.environ.get(\"CUDA_VISIBLE_DEVICES\"))\n",
    "print(\"Built with CUDA:\", torch.version.cuda)     \n",
    "print(\"CUDA available?:\", torch.cuda.is_available())  \n",
    "print(\"Device count:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper for data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnlabeledWrapper(Dataset):\n",
    "    \"\"\"Return images only; label is always -1.\"\"\"\n",
    "    def __init__(self, base_ds, indices):\n",
    "        self.base_ds = base_ds\n",
    "        self.indices = indices\n",
    "    def __len__(self):\n",
    "        return len(self.indices)\n",
    "    def __getitem__(self, i):\n",
    "        x, _ = self.base_ds[self.indices[i]]\n",
    "        return x, -1\n",
    "\n",
    "\n",
    "def configure_mnist(batch_size=100, n_labeled=1000, val_fraction=0.10, seed=42):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Lambda(lambda x: x.view(-1))          # flatten to 784\n",
    "    ])\n",
    "\n",
    "    full_train = datasets.MNIST(root='./data', train=True,  download=True, transform=transform)\n",
    "    test_ds    = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    rng = np.random.RandomState(seed)\n",
    "    all_idx       = np.arange(len(full_train))                       # 60 000 indices\n",
    "    labeled_idx   = rng.choice(all_idx, size=n_labeled, replace=False)\n",
    "    remaining_idx = np.setdiff1d(all_idx, labeled_idx)\n",
    "\n",
    "    n_val   = int(len(remaining_idx) * val_fraction)\n",
    "    val_idx = rng.choice(remaining_idx, size=n_val, replace=False)\n",
    "    unlabeled_idx = np.setdiff1d(remaining_idx, val_idx)\n",
    "\n",
    "    labeled_ds     = Subset(full_train, labeled_idx)                 # (x, y)\n",
    "    val_ds         = Subset(full_train, val_idx)                     # (x, y)\n",
    "    unlabeled_ds   = UnlabeledWrapper(full_train, unlabeled_idx)     # (x, -1)\n",
    "\n",
    "    train_labeled_loader   = DataLoader(labeled_ds,   batch_size=batch_size, shuffle=True,  drop_last=True)\n",
    "    train_unlabeled_loader = DataLoader(unlabeled_ds, batch_size=batch_size, shuffle=True,  drop_last=True)\n",
    "    val_loader             = DataLoader(val_ds,       batch_size=batch_size, shuffle=False)\n",
    "    test_loader            = DataLoader(test_ds,      batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    X_lab = torch.stack([x for x, _ in labeled_ds])\n",
    "    Y_lab = torch.tensor([y for _, y in labeled_ds])\n",
    "\n",
    "    X_val = torch.stack([x for x, _ in val_ds])\n",
    "    Y_val = torch.tensor([y for _, y in val_ds])\n",
    "\n",
    "    X_test = torch.stack([x for x, _ in test_ds])\n",
    "    Y_test = test_ds.targets.clone()\n",
    "\n",
    "    return (X_lab, X_val, X_test,\n",
    "            Y_lab, Y_val, Y_test,\n",
    "            train_labeled_loader, train_unlabeled_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below you can set up any hyperparameters for the experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 50\n",
    "GAUSSIAN_NOISE = True\n",
    "INPUT_DIM = 784\n",
    "BATCH_SIZE = 100\n",
    "AE_HIDDEN = 1000\n",
    "DC_HIDDEN = 1000\n",
    "LATENT_DIM_CAT = 10\n",
    "LATENT_DIM_STYLE = 10\n",
    "PRIOR_STD = 1.0\n",
    "RESULT_FOLDER = 'results_5000_epochs_2000 samples'\n",
    "NUM_LABELED = 100\n",
    "\n",
    "recon_loss = nn.MSELoss()\n",
    "init_recon_lr = 0.01\n",
    "\n",
    "semi_sup_loss = nn.CrossEntropyLoss()\n",
    "init_semi_sup_lr = 0.1\n",
    "\n",
    "init_gen_lr = init_disc_lr = 0.1\n",
    "use_decoder_sigmoid = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the data laoders. This includes a labeled training data laoder, unlabeled training data loader, as well as data laoders for valiudation and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_lab, X_val, X_test,\n",
    " Y_lab, Y_val, Y_test,\n",
    " train_labeled_loader,\n",
    " train_unlabeled_loader,\n",
    " val_loader,\n",
    " test_loader) = configure_mnist(batch_size=BATCH_SIZE, n_labeled=NUM_LABELED)\n",
    "\n",
    "print(\"labelled   :\", len(train_labeled_loader.dataset))   # 1 000\n",
    "print(\"unlabelled :\", len(train_unlabeled_loader.dataset)) # ≈53 000\n",
    "print(\"val        :\", len(val_loader.dataset))             # ≈6 000\n",
    "print(Y_lab.max(), Y_lab.min())      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = SemiSupervisedAutoEncoderOptions(\n",
    "    input_dim=INPUT_DIM,\n",
    "    ae_hidden_dim=AE_HIDDEN,\n",
    "    disc_hidden_dim=DC_HIDDEN,\n",
    "    latent_dim_categorical=LATENT_DIM_CAT,\n",
    "    latent_dim_style=LATENT_DIM_STYLE,\n",
    "    recon_loss_fn=recon_loss,\n",
    "    init_recon_lr=init_recon_lr,\n",
    "    semi_supervised_loss_fn=semi_sup_loss,\n",
    "    init_semi_sup_lr=init_semi_sup_lr,\n",
    "    init_gen_lr=init_gen_lr,\n",
    "    use_decoder_sigmoid=use_decoder_sigmoid,\n",
    "    init_disc_categorical_lr = init_disc_lr,\n",
    "    init_disc_style_lr = init_disc_lr\n",
    ")\n",
    "\n",
    "model = SemiSupervisedAdversarialAutoencoder(options);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the training, weighst get saved automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_mbgd_2(\n",
    "    val_loader=val_loader,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    prior_std=PRIOR_STD,\n",
    "    result_folder=RESULT_FOLDER,\n",
    "    add_gaussian_noise=GAUSSIAN_NOISE,\n",
    "    train_labeled_loader=train_labeled_loader,\n",
    "    train_unlabeled_loader=train_unlabeled_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can load the weights from any previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"path_to_result_folder/weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating classifcation accuracy of the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_probs, all_preds = [], []\n",
    "for imgs, _ in test_loader:\n",
    "    probs, preds = model.predict(imgs)\n",
    "    all_probs.append(probs.cpu())\n",
    "    all_preds.append(preds.cpu())\n",
    "\n",
    "all_probs = torch.cat(all_probs, dim=0)\n",
    "all_preds = torch.cat(all_preds, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_correct = torch.eq(all_preds, Y_test).sum().item()\n",
    "accuracy = num_correct / Y_test.size(0)\n",
    "print(f\"Test accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genrate a single image of a digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img7 = model.generate_images(1, prior_std=0.001)\n",
    "plt.imshow(img7.squeeze().cpu().numpy(), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate digits from 0 to 9 with random style code sampled froma  gaussian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "fig, axes = plt.subplots(\n",
    "    nrows=10,\n",
    "    ncols=10,\n",
    "    figsize=(10, 10),\n",
    "    tight_layout=True\n",
    ")\n",
    "\n",
    "for digit in range(10):\n",
    "    labels = torch.full(\n",
    "        (10,),\n",
    "        fill_value=digit,\n",
    "        dtype=torch.long,\n",
    "        device=model.device\n",
    "    )\n",
    "    \n",
    "    imgs = model.generate_images(labels, style_z=None, prior_std=PRIOR_STD)\n",
    "    for col in range(10):\n",
    "        ax = axes[digit, col]\n",
    "        img = imgs[col].squeeze().cpu().numpy()\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "fig.savefig(f'{RESULT_FOLDER}/digits_0_to_9', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genrate same digit with different style representations to investigate the correlation of the latent vector with image style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "digit = 3  \n",
    "n = 10 \n",
    "grid_range = 5.0\n",
    "\n",
    "style_grid_x = np.linspace(-grid_range, grid_range, n)\n",
    "style_grid_y = np.linspace(-grid_range, grid_range, n)\n",
    "\n",
    "fig, axes = plt.subplots(n, n, figsize=(10, 10), tight_layout=True)\n",
    "\n",
    "style_z = torch.zeros((n * n, model.options.latent_dim_style), device=model.device)\n",
    "for i, sx in enumerate(style_grid_x):\n",
    "    for j, sy in enumerate(style_grid_y):\n",
    "        idx = i * n + j\n",
    "        style_z[idx, 0] = sx  # first style dim\n",
    "        style_z[idx, 1] = sy  # second style dim\n",
    "        # if more style dims, leave them as 0\n",
    "\n",
    "\n",
    "labels = torch.full((n * n,), fill_value=digit, dtype=torch.long, device=model.device)\n",
    "imgs = model.generate_images(labels, style_z=style_z)\n",
    "\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        ax = axes[i, j]\n",
    "        idx = i * n + j\n",
    "        img = imgs[idx].squeeze().cpu().numpy()\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.axis('off')\n",
    "\n",
    "\n",
    "fig.savefig(f'{RESULT_FOLDER}/digit_{digit}_varying_style', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
